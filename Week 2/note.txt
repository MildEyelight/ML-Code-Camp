This file is used to recode the process complementing the Tutorial of DGL with the node classification mission.
Tutorial website: (https://docs.dgl.ai/tutorials/blitz/index.html)
1. DGL 
DGL model is a python package used for analysis the graph data and construct the GNN structure.
I acquired the basic knowlegde of graph and machine learning on graph through the course CS224w of Stanford.

1.1 Graph stored in DGL
DGL uses the container(torch.Tensor) to store graph data of the information containing{node,edge,label of node,
label of edge,mask of training node,mask of test node,etc.}

1.2 dgl.nn.GraphConv()
Graph Convoluntional Layer in DGL.

2.GNN/GCN model
GCN is a main variant of GNN and is used as basic structure of neural network in this mission of node classification.
In tutorial, the common structure of GNN is adopted by author to help us understand GNN and by more to build our own
specific GNNs.

3.Node classification(/Week2/GCN for Node Classification.py)
According to the tutorial of DGL, we are going to implement a semi-supervised node classification mission.

4.Refine process for node classification in DGL example code 
    Before         After              Result
(1) ReLU()    -->  sigmoid()          0.77-->0.69
(2) 2 Layer   -->  1 Layer            0.77-->0.67
(3) 2 Layer   -->  3 Layer            0.77-->0.75
(4) refine num_features               almost invariant
(5) noselfloop-->  selfloop           0.77-->0.79

Self loop is a very important process in GCN message passing progress to contain self-node-message in next layer
At first i think the function GraphConv() will contain the process A = A + I but actually not, so i added Self-loop
and the result increase 2 points.

Hyperparameters of (5): Acc = 0.792
hidden_feature = 16
Layer = 2
with Self-loop

In refine(1)-(4), the loss decrease to 0.001 after 100 epoches, the mode may have some over-fitting tendency,and with
the studying parameters increasing, the over-fitting tendency goes stronger and thus causing the result worse.
